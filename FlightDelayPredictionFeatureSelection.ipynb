{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_excel(\"D:/Suyog's Docs/Data/FlightData/AmericanAIData.xlsx\")#,header=None, names=flight_headers, dtype=flight_dtypes) #, header =[1])\n",
    "flights.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_percentage (df, col_name):\n",
    "    dfcount = df.groupby(col_name)\n",
    "    counts = dfcount.count()\n",
    "    percentage = round(dfcount.count().mean() * 100, 1)\n",
    "    percentages = percentage.sort_values()\n",
    "    null_values = pd.concat([counts, percentages], axis=1, keys=[\"counts\", \"%\"])\n",
    "    return counts.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_name(df, lit):\n",
    "    feature_col_name = df[[lit]]\n",
    "    col_name = feature_col_name.columns.values\n",
    "    return col_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "American_Al = flights.loc[flights[\"DEST_AIRPORT\"] == 'Seattle-Tacoma International Airport']\n",
    "American_Al.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert timestamp to proper value\n",
    "def insertChar(mystring ):\n",
    "    lenofstring = len(mystring)\n",
    "    if (lenofstring == 1):\n",
    "        mystring = '0' + mystring[0:] +':' + '00'\n",
    "    elif (lenofstring == 2):\n",
    "        if (int(mystring[0:2]) <= 24):\n",
    "            mystring = mystring[:] + ':00'\n",
    "        else :\n",
    "            mystring =  '00:' +mystring \n",
    "    elif (lenofstring == 3):\n",
    "        if (int(mystring[0:2]) <= 24):\n",
    "            mystring = mystring[0:2] + ':' + mystring[2:3] + '0'\n",
    "        else:    \n",
    "            mystring = '0' + mystring[1:] + ':00'\n",
    "    elif (lenofstring > 4):\n",
    "        mystring = mystring[0:4]\n",
    "        mystring = mystring[0:2] + ':' + mystring[2:] \n",
    "    elif (lenofstring == 4):\n",
    "        mystring = mystring[0:2] + ':' + mystring[2:]\n",
    "    return mystring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert timestamps into proper format\n",
    "American_Al[\"TIMESTAMP\"] = pd.to_datetime(American_Al['YEAR']+ American_Al['MONTH']+ American_Al['DAY']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "American_Al[\"DEPARTURE_TIME\"] = American_Al[\"DEPARTURE_TIME\"].astype(str).apply(insertChar)\n",
    "American_Al[\"SCHEDULED_DEPARTURE\"] =American_Al[\"SCHEDULED_DEPARTURE\"].astype(str).apply(insertChar)\n",
    "American_Al[\"SCHEDULED_ARRIVAL\"] =American_Al[\"SCHEDULED_ARRIVAL\"].astype(str).apply(insertChar)\n",
    "American_Al[\"ARRIVAL_TIME\"] =American_Al[\"ARRIVAL_TIME\"].astype(str).apply(insertChar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "American_Al.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(American_Al.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get monthwise count for simplicity we will consider only two months data\n",
    "col_name = get_cols_name(American_Al,'MONTH')\n",
    "print(get_count_percentage(American_Al, col_name))\n",
    "American = American_Al.loc[(American_Al['MONTH'] == 7) | (American_Al['MONTH'] == 8)]\n",
    "American_Al.head(5)\n",
    "#American_Al = pd.DataFrame(American_Al) #.to_frame().reset_index()\n",
    "print(get_count_percentage(American, col_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For simplicti we wil take onlu Aug and July data\n",
    "American = flights.loc[flights[\"DEST_AIRPORT\"] == 'Seattle-Tacoma International Airport']\n",
    "American.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "American[\"MONTHDAY\"] = American[\"MONTH\"].astype(str) +  American[\"DAY\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the month day wise graph to check if delyas are higher\n",
    "sns.set()\n",
    "sns.set(rc={'figure.figsize':(100,40)})\n",
    "plot = sns.barplot(x='MONTHDAY',y='ARRIVAL_DELAY',data=American)\n",
    "colors = sns.color_palette('bright')[0:5]\n",
    "plot.set_title(\"Daywise  delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histrogram to determin delay intervalswith bin size of 5 mins\n",
    "sns.set()\n",
    "sns.set(rc={'figure.figsize':(30,20)})\n",
    "#histogram_data = sns.load_dataset(\"American\")\n",
    "#sns.histplot(data=histogram_data , x=\"ARRIVAL_DELAY\", bins=10)\n",
    "American[\"ARRIVAL_DELAY\"].hist(bins=10)\n",
    "plt.xlabel(\"Arrival Delays in mins\", fontsize=40)\n",
    "plt.ylabel(\"Frequency\",fontsize=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Histogram, we can say the target data is not balanced, most of the time there is no delay or before arrival time. \n",
    "# let su get percentile of the arrival delays to understand pattern, also we can convert the data into three categoreis\n",
    "# Before time (arrival delay < 0), on time ( arrival delay < 10 mins)  and delayed (arrival dealy > 10 mins). We can calculate\n",
    "#entropy of the data using above categories\n",
    "# get arrival edlay and days from the dataframe\n",
    "arrival_delays = American[[\"ARRIVAL_DELAY\",\"MONTHDAY\"]]\n",
    "arrival_delays.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentile(df,col,percentile_keys):\n",
    "    counts ={}\n",
    "    i = 0 \n",
    "    print(col)\n",
    "    percentile = df[[col]].quantile(percentile_keys)\n",
    "    #create list on datframe \n",
    "    percentages = percentile[col].tolist()\n",
    "    for percent in percentages:\n",
    "        count = (df[df[col] < percent].shape[0])\n",
    "        counts[percentile_keys[i]] = count\n",
    "        i = i+1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_keys = [0.25, 0.90]\n",
    "#we need to get value counts below 25 % abd above 95% percentile to see how extrem delays are there \n",
    "# get first ranges  0f 25% and 95%\n",
    "percentile = arrival_delays[[\"ARRIVAL_DELAY\"]].quantile(percentile_keys)\n",
    "percent = arrival_delays[\"ARRIVAL_DELAY\"].tolist()\n",
    "counts = {} \n",
    "counts['below 0.25'] = (arrival_delays[arrival_delays.ARRIVAL_DELAY < percent[0]].shape[0])\n",
    "counts ['moderate delays'] = (arrival_delays[(arrival_delays.ARRIVAL_DELAY > percent[0]) & (arrival_delays.ARRIVAL_DELAY < percent[1])].shape[0])\n",
    "counts ['extreme delays'] = (arrival_delays[arrival_delays.ARRIVAL_DELAY > percent[1]].shape[0])\n",
    "print(counts)\n",
    "#print(arrival_delays[arrival_delays.ARRIVAL_DELAY < -5.0].shape[0])\n",
    "# we will drop extreme delays as the outlier will overfit the model\n",
    "print(percentile)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "American = American[(American.ARRIVAL_DELAY < 37) & (American.ARRIVAL_DELAY > -15)]\n",
    "American.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AS dataframe consist of both numerical and categorical data, only continous data needs to be scaled / normalized. \n",
    "#Below function will use standard deviation method to normalize column data\n",
    "# input column name and dataframe\n",
    "def normalize_cols(df, col_name): \n",
    "    df[col_name] -= df[col_name].mean()\n",
    "    df[col_name] /= df[col_name].std()\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the select cols and normalize them\n",
    "List_of_cols = [\"DEPARTURE_DELAY\", \"TAXI_OUT\", \"WHEELS_OFF\", \"SCHEDULED_TIME\", \"ELAPSED_TIME\", \"AIR_TIME\", \"WHEELS_ON\", \"TAXI_IN\", \"ARRIVAL_DELAY\"] \n",
    "for cols in List_of_cols:\n",
    "    American[cols] = normalize_cols(American[[cols]].astype(float),cols)\n",
    "American.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From above graph we can see there are days where delays are extreme. This will lead to overfitting of the model. \n",
    "#plot them as box plot. Before that we need to normalize data\n",
    "american_airline_outliers = American[[\"MONTHDAY\" ,\"DEPARTURE_DELAY\", \"TAXI_OUT\", \"WHEELS_OFF\", \"ELAPSED_TIME\", \"AIR_TIME\", \"WHEELS_ON\", \"TAXI_IN\", \"ARRIVAL_DELAY\"]].astype(float)\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "col_names = american_airline_outliers.columns\n",
    "d = scaler.fit_transform(american_airline_outliers)\n",
    "scaled_data = pd.DataFrame(d, columns=[\"DEPARTURE_DELAY\", \"TAXI_OUT\", \"WHEELS_OFF\", \"ELAPSED_TIME\", \"AIR_TIME\", \"WHEELS_ON\", \"TAXI_IN\", \"ARRIVAL_DELAY\"])\n",
    "scaled_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create another dataframe and plot graph\n",
    "American.head()\n",
    "#american_ariline_outliers = American_Al.loc[American_Al[\"DEPARTURE_DELAY\"], American_Al[\"TAXI_OUT\"], American_Al[\"WHEELS_OFF\"], American_Al[\"ELAPSED_TIME\"], American_Al [\"AIR_TIME\"], American_Al[\"WHEELS_ON\"], American_Al[\"TAXI_IN\"],American_Al[\"ARRIVAL_DELAY\"]]\n",
    "\n",
    "#american_airline_outliers.head()\n",
    "#figure, axes = plt.subplots(2,4, sharex=True, figsize=(10,20))\n",
    "colors = sns.color_palette('bright')[0:5]\n",
    "sns.set(rc={'figure.figsize':(40,25)})\n",
    "#scaled_data.boxplot(column=[\"DEPARTURE_DELAY\", \"TAXI_OUT\", \"WHEELS_OFF\", \"ELAPSED_TIME\"],by=[\"MONTHDAY\"], layout=(2,2),fontsize=20)\n",
    "American.boxplot(column=[\"DEPARTURE_DELAY\", \"TAXI_OUT\", \"WHEELS_OFF\", \"ELAPSED_TIME\"],by=[\"MONTHDAY\"],layout=(2,2),fontsize=20)\n",
    "                                          \n",
    "\n",
    "#ax_1 = american_airline_outliers.boxplot(column=[\"AIR_TIME\", \"WHEELS_ON\", \"TAXI_IN\", \"ARRIVAL_DELAY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette('bright')[0:5]\n",
    "sns.set(rc={'figure.figsize':(30,25)})\n",
    "#scaled_data.boxplot(column=[\"DEPARTURE_DELAY\", \"TAXI_OUT\", \"WHEELS_OFF\", \"ELAPSED_TIME\"],by=[\"MONTHDAY\"], layout=(2,2),fontsize=20)\n",
    "American.boxplot(column=[\"AIR_TIME\", \"WHEELS_ON\", \"TAXI_IN\", \"ARRIVAL_DELAY\"],by=[\"MONTHDAY\"],layout=(2,2),fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot correlation and covarinace between Taxiin, out departure delay, arrival  delay elapsed time and airtime to see if any relation\n",
    "Amreican_features = American[[\"DEPARTURE_DELAY\", \"TAXI_OUT\", \"WHEELS_OFF\", \"SCHEDULED_TIME\", \"ELAPSED_TIME\",\"AIR_TIME\", \"WHEELS_ON\", \"TAXI_IN\", \"ARRIVAL_DELAY\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(df,size=10):\n",
    "    \"\"\"Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n",
    "\n",
    "    Input:\n",
    "        df: pandas DataFrame\n",
    "        size: vertical and horizontal size of the plot\n",
    "    \"\"\"\n",
    "\n",
    "    corr = df.corr()\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    #ax.matshow(corr)\n",
    "    #plt.xticks(range(len(corr.columns)), corr.columns)\n",
    "    #plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    sns.heatmap(corr,annot=True, mask=np.zeros_like(corr,dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(Amreican_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot correlation matrix- pairplot \n",
    "sns.pairplot(Amreican_features, hue ='ARRIVAL_DELAY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot covariance matrix\n",
    "def correlated_cols(dataframe,threshold):\n",
    "    col_corr = set()\n",
    "    corr_matrix = dataframe.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range (i):\n",
    "            if abs(corr_matrix.iloc[i,j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = correlated_cols(Amreican_features,0.9)\n",
    "print(columns_to_drop)\n",
    "American.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping column from the dataset having high correlation to avoid the overfitting \n",
    "Features =  American.drop(columns_to_drop,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the covariance of the numerical data\n",
    "Amreican_features.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amreican_features.corr()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#AS per feature we will drop categorical columns having no variance nad important feature will do one-hot encoding.\n",
    "Features.head(5)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features.head(5)\n",
    "def get_nun_unique_count(df,colname):\n",
    "    #n = df.colname.nunique()\n",
    "    n = df[colname].nunique()\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = set()\n",
    "for col in Features.columns:\n",
    "    if (get_nun_unique_count(Features,col) < 10):\n",
    "        cols_to_drop.add(col)\n",
    "#print(cols_to_drop)\n",
    "Features_Selected = Features.drop(cols_to_drop,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Features_Selected.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us convert the arrival time and departure time into the 4 bins mid night(00:00 - 06:00), morning (06:00-12:00), afternoon(12:00-18:00), night (18:00-24:00)\n",
    "bins = [ 600,1200,1800,2400,np.inf]\n",
    "names = ['night' ,'earlymorning', 'morning' ,'afternoon']\n",
    "Features_Selected['DEPARTURE_TIME'] = pd.cut(Features_Selected['DEPARTURE_TIME'], bins, labels=names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_Selected['ARRIVAL_TIME'] = pd.cut(Features_Selected['ARRIVAL_TIME'], bins, labels=names)\n",
    "Features_Selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us drop Month, day,  SCHEDULED_DEPARTURE, SCHEDULED_ARRIVAL and MONTHDAY coloumn as those are not significant\n",
    "American_al_features = Features_Selected.drop(['SCHEDULED_DEPARTURE', 'SCHEDULED_ARRIVAL', 'MONTH', 'DAY', 'MONTHDAY'],axis=1)\n",
    "American_al_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if flight_number and tail number for unique value. Looks liie they will be repeating for each ferry and do not make any significance\n",
    "print(\"Flight Number Unique records\", American_al_features['FLIGHT_NUMBER'].nunique())\n",
    "print(\"TAIL Number Unique records\" , American_al_features['TAIL_NUMBER'].nunique())\n",
    "print(\"Total Counts\" , American_al_features.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the unique values are less compare to total counts, the flight numebrs and tail numbers are repeating everytime. This wont be useful and needs to \n",
    "# drop further.\n",
    "American_al_data =  American_al_features.drop(['FLIGHT_NUMBER','TAIL_NUMBER'],axis=1)\n",
    "American_al_data.head(5)\n",
    "#DEPARTURE_TIME and ARRIVAL_TIME  are the categorical value which needs to be converted into numerical data. We need to apply one-hot encoding\n",
    "dummy_departure_time = pd.get_dummies(American_al_data.DEPARTURE_TIME)\n",
    "dummy_arrival_time = pd.get_dummies(American_al_data.ARRIVAL_TIME)\n",
    "# add suffix to dummy col name to avoid dupaice columns\n",
    "dummy_departure_time = dummy_departure_time.add_prefix('departure_time_')\n",
    "dummy_arrival_time = dummy_arrival_time.add_prefix('arrival_time_')\n",
    "#join newly created departure and arrival time \n",
    "American_dl_dummy_departure = pd.concat([American_al_data,dummy_departure_time],axis='columns')\n",
    "#American_dl_dummy_departure.head()\n",
    "American_dl_dummy_arrival = pd.concat([American_dl_dummy_departure,dummy_arrival_time],axis='columns')\n",
    "American_dl_dummy_arrival.head()\n",
    "#let us drop orginal catgory column from the Df\n",
    "America_Al_Features = American_dl_dummy_arrival.drop(['DEPARTURE_TIME','ARRIVAL_TIME'],axis=1 )\n",
    "#to avoid dummy variable trap or multi colinearity , we need to drop one columns from the dummy variables created \n",
    "#dropping deparutre_time_night and arrival_time_night from the dataframe\n",
    "America_Al_Features = American_dl_dummy_arrival.drop(['DEPARTURE_TIME','ARRIVAL_TIME','departure_time_night','arrival_time_night'],axis=1 )\n",
    "America_Al_Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "American_Al_data = America_Al_Features\n",
    "American_Al_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we have converted and selected all the features that can be apply to ML model, we need to idenify most important features\n",
    "#this can be achiveved using information gain\n",
    "#get dependent variable\n",
    "\n",
    "\n",
    "y_lable = America_Al_Features.pop('ARRIVAL_DELAY')\n",
    "x_lable = America_Al_Features\n",
    "\n",
    "#import required libaraires\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "# feature selection\n",
    "f_selector = SelectKBest(score_func=f_regression, k='all')\n",
    "# learn relationship from training data\n",
    "f_selector.fit(x_lable, y_lable)\n",
    "# transform train input data\n",
    "X_train_fs = f_selector.transform(x_lable)\n",
    "# Plot the scores for the features\n",
    "plt.bar([i for i in range(len(f_selector.scores_))], f_selector.scores_)\n",
    "plt.xlabel(\"feature index\")\n",
    "plt.ylabel(\"F-value (transformed from the correlation values)\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "American_Al_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From above , thecolumn # 0,1,2,3,5,7,9 and 10 have significant imapct and we will drop column 4,6 from the dataframe and save the same.\n",
    "# column 4, 6, 8 are wheeels_on, departure_time_earlymorning, arrival_time_earlymorning and arrival_time_afternoon . we will drop wheels_on.\n",
    "Flight_delay_prediction_features = American_Al_data.drop(['WHEELS_ON'],axis=1)\n",
    "Flight_delay_prediction_features.head(5)\n",
    "Flight_delay_prediction_features.to_csv(\"D:/Suyog's Docs/Data/FlightData/features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
